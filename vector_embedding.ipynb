{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce5859f0-45e8-43b9-9320-90a1bd5c4ae5",
   "metadata": {},
   "source": [
    "# Importing Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45049f2f-6532-45ab-b798-7c80b9474a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Gensim downloader module\n",
    "# Gensim is a popular NLP library used for working with word embeddings, topic modeling, etc.\n",
    "import gensim.downloader as api\n",
    "\n",
    "# Load a pre-trained Word2Vec model trained on Google News dataset\n",
    "# \"word2vec-google-news-300\" means:\n",
    "#   - It's the Word2Vec model released by Google.\n",
    "#   - Trained on ~100 billion words from Google News.\n",
    "#   - Each word is represented by a 300-dimensional vector.\n",
    "# The 'api.load()' function automatically downloads and loads the model if not already cached.\n",
    "model = api.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4582806a-8694-448f-95f5-5bee24107056",
   "metadata": {},
   "source": [
    "# Example of Word as a Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3a7eae8-23a1-45cc-a1f4-a9c48599e0a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.07421875e-01 -2.01171875e-01  1.23046875e-01  2.11914062e-01\n",
      " -9.13085938e-02  2.16796875e-01 -1.31835938e-01  8.30078125e-02\n",
      "  2.02148438e-01  4.78515625e-02  3.66210938e-02 -2.45361328e-02\n",
      "  2.39257812e-02 -1.60156250e-01 -2.61230469e-02  9.71679688e-02\n",
      " -6.34765625e-02  1.84570312e-01  1.70898438e-01 -1.63085938e-01\n",
      " -1.09375000e-01  1.49414062e-01 -4.65393066e-04  9.61914062e-02\n",
      "  1.68945312e-01  2.60925293e-03  8.93554688e-02  6.49414062e-02\n",
      "  3.56445312e-02 -6.93359375e-02 -1.46484375e-01 -1.21093750e-01\n",
      " -2.27539062e-01  2.45361328e-02 -1.24511719e-01 -3.18359375e-01\n",
      " -2.20703125e-01  1.30859375e-01  3.66210938e-02 -3.63769531e-02\n",
      " -1.13281250e-01  1.95312500e-01  9.76562500e-02  1.26953125e-01\n",
      "  6.59179688e-02  6.93359375e-02  1.02539062e-02  1.75781250e-01\n",
      " -1.68945312e-01  1.21307373e-03 -2.98828125e-01 -1.15234375e-01\n",
      "  5.66406250e-02 -1.77734375e-01 -2.08984375e-01  1.76757812e-01\n",
      "  2.38037109e-02 -2.57812500e-01 -4.46777344e-02  1.88476562e-01\n",
      "  5.51757812e-02  5.02929688e-02 -1.06933594e-01  1.89453125e-01\n",
      " -1.16210938e-01  8.49609375e-02 -1.71875000e-01  2.45117188e-01\n",
      " -1.73828125e-01 -8.30078125e-03  4.56542969e-02 -1.61132812e-02\n",
      "  1.86523438e-01 -6.05468750e-02 -4.17480469e-02  1.82617188e-01\n",
      "  2.20703125e-01 -1.22558594e-01 -2.55126953e-02 -3.08593750e-01\n",
      "  9.13085938e-02  1.60156250e-01  1.70898438e-01  1.19628906e-01\n",
      "  7.08007812e-02 -2.64892578e-02 -3.08837891e-02  4.06250000e-01\n",
      " -1.01562500e-01  5.71289062e-02 -7.26318359e-03 -9.17968750e-02\n",
      " -1.50390625e-01 -2.55859375e-01  2.16796875e-01 -3.63769531e-02\n",
      "  2.24609375e-01  8.00781250e-02  1.56250000e-01  5.27343750e-02\n",
      "  1.50390625e-01 -1.14746094e-01 -8.64257812e-02  1.19140625e-01\n",
      " -7.17773438e-02  2.73437500e-01 -1.64062500e-01  7.29370117e-03\n",
      "  4.21875000e-01 -1.12792969e-01 -1.35742188e-01 -1.31835938e-01\n",
      " -1.37695312e-01 -7.66601562e-02  6.25000000e-02  4.98046875e-02\n",
      " -1.91406250e-01 -6.03027344e-02  2.27539062e-01  5.88378906e-02\n",
      " -3.24218750e-01  5.41992188e-02 -1.35742188e-01  8.17871094e-03\n",
      " -5.24902344e-02 -1.74713135e-03 -9.81445312e-02 -2.86865234e-02\n",
      "  3.61328125e-02  2.15820312e-01  5.98144531e-02 -3.08593750e-01\n",
      " -2.27539062e-01  2.61718750e-01  9.86328125e-02 -5.07812500e-02\n",
      "  1.78222656e-02  1.31835938e-01 -5.35156250e-01 -1.81640625e-01\n",
      "  1.38671875e-01 -3.10546875e-01 -9.71679688e-02  1.31835938e-01\n",
      " -1.16210938e-01  7.03125000e-02  2.85156250e-01  3.51562500e-02\n",
      " -1.01562500e-01 -3.75976562e-02  1.41601562e-01  1.42578125e-01\n",
      " -5.68847656e-02  2.65625000e-01 -2.09960938e-01  9.64355469e-03\n",
      " -6.68945312e-02 -4.83398438e-02 -6.10351562e-02  2.45117188e-01\n",
      " -9.66796875e-02  1.78222656e-02 -1.27929688e-01 -4.78515625e-02\n",
      " -7.26318359e-03  1.79687500e-01  2.78320312e-02 -2.10937500e-01\n",
      " -1.43554688e-01 -1.27929688e-01  1.73339844e-02 -3.60107422e-03\n",
      " -2.04101562e-01  3.63159180e-03 -1.19628906e-01 -6.15234375e-02\n",
      "  5.93261719e-02 -3.23486328e-03 -1.70898438e-01 -3.14941406e-02\n",
      " -8.88671875e-02 -2.89062500e-01  3.44238281e-02 -1.87500000e-01\n",
      "  2.94921875e-01  1.58203125e-01 -1.19628906e-01  7.61718750e-02\n",
      "  6.39648438e-02 -4.68750000e-02 -6.83593750e-02  1.21459961e-02\n",
      " -1.44531250e-01  4.54101562e-02  3.68652344e-02  3.88671875e-01\n",
      "  1.45507812e-01 -2.55859375e-01 -4.46777344e-02 -1.33789062e-01\n",
      " -1.38671875e-01  6.59179688e-02  1.37695312e-01  1.14746094e-01\n",
      "  2.03125000e-01 -4.78515625e-02  1.80664062e-02 -8.54492188e-02\n",
      " -2.48046875e-01 -3.39843750e-01 -2.83203125e-02  1.05468750e-01\n",
      " -2.14843750e-01 -8.74023438e-02  7.12890625e-02  1.87500000e-01\n",
      " -1.12304688e-01  2.73437500e-01 -3.26171875e-01 -1.77734375e-01\n",
      " -4.24804688e-02 -2.69531250e-01  6.64062500e-02 -6.88476562e-02\n",
      " -1.99218750e-01 -7.03125000e-02 -2.43164062e-01 -3.66210938e-02\n",
      " -7.37304688e-02 -1.77734375e-01  9.17968750e-02 -1.25000000e-01\n",
      " -1.65039062e-01 -3.57421875e-01 -2.85156250e-01 -1.66992188e-01\n",
      "  1.97265625e-01 -1.53320312e-01  2.31933594e-02  2.06054688e-01\n",
      "  1.80664062e-01 -2.74658203e-02 -1.92382812e-01 -9.61914062e-02\n",
      " -1.06811523e-02 -4.73632812e-02  6.54296875e-02 -1.25732422e-02\n",
      "  1.78222656e-02 -8.00781250e-02 -2.59765625e-01  9.37500000e-02\n",
      " -7.81250000e-02  4.68750000e-02 -2.22167969e-02  1.86767578e-02\n",
      "  3.11279297e-02  1.04980469e-02 -1.69921875e-01  2.58789062e-02\n",
      " -3.41796875e-02 -1.44042969e-02 -5.46875000e-02 -8.78906250e-02\n",
      "  1.96838379e-03  2.23632812e-01 -1.36718750e-01  1.75781250e-01\n",
      " -1.63085938e-01  1.87500000e-01  3.44238281e-02 -5.63964844e-02\n",
      " -2.27689743e-05  4.27246094e-02  5.81054688e-02 -1.07910156e-01\n",
      " -3.88183594e-02 -2.69531250e-01  3.34472656e-02  9.81445312e-02\n",
      "  5.63964844e-02  2.23632812e-01 -5.49316406e-02  1.46484375e-01\n",
      "  5.93261719e-02 -2.19726562e-01  6.39648438e-02  1.66015625e-02\n",
      "  4.56542969e-02  3.26171875e-01 -3.80859375e-01  1.70898438e-01\n",
      "  5.66406250e-02 -1.04492188e-01  1.38671875e-01 -1.57226562e-01\n",
      "  3.23486328e-03 -4.80957031e-02 -2.48046875e-01 -6.20117188e-02]\n"
     ]
    }
   ],
   "source": [
    "word_vectors = model\n",
    "\n",
    "#let us look how the vecctor embedding of a word looks like\n",
    "print(word_vectors['computer'])  #Example: accessing the vector for the word 'computer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd61f2a5-6ba7-47c7-8749-0b2aad7f984b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "#getting to know the shape of the vector for word cat\n",
    "print(word_vectors['cat'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333b23a2-9785-4882-95af-c0403641792c",
   "metadata": {},
   "source": [
    "# Similar Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77caaf37-592d-4a57-b7d1-6434e568970f",
   "metadata": {},
   "source": [
    "### King + Woman - Man = ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2654275-f0e8-489a-ae9c-ad8e98a6e556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('queen', 0.7118193507194519), ('monarch', 0.6189674139022827), ('princess', 0.5902431011199951), ('crown_prince', 0.5499460697174072), ('prince', 0.5377321839332581), ('kings', 0.5236844420433044), ('Queen_Consort', 0.5235945582389832), ('queens', 0.518113374710083), ('sultan', 0.5098593235015869), ('monarchy', 0.5087411403656006)]\n"
     ]
    }
   ],
   "source": [
    "# Find words that complete the analogy: king - man + woman â‰ˆ ?\n",
    "# 'positive' terms are ADDED:  vec('king') + vec('woman')\n",
    "# 'negative' terms are SUBTRACTED: - vec('man')\n",
    "# The method computes a target vector = sum(positive) - sum(negative),\n",
    "# then returns the top 10 vocabulary words with highest cosine similarity\n",
    "# to that target vector (excluding the input words themselves).\n",
    "print(\n",
    "    word_vectors.most_similar(\n",
    "        positive=['king', 'woman'],  # add these vectors\n",
    "        negative=['man'],            # subtract this vector\n",
    "        topn=10                      # return 10 nearest neighbors\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db12a1c-bd58-446d-91ad-1fbd81a8314f",
   "metadata": {},
   "source": [
    "the above is the list of top 10 answers and out from them queen is the one which has the highest probablity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e67e98fa-cc7a-45c7-8f6c-5a36592cd037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.76640123\n",
      "0.6510957\n",
      "0.7643474\n",
      "0.8543272\n",
      "0.7594367\n",
      "0.11408084\n"
     ]
    }
   ],
   "source": [
    "#checking the similarity between a few pair of words\n",
    "\n",
    "print(word_vectors.similarity('woman','man'))\n",
    "print(word_vectors.similarity('king','queen'))\n",
    "print(word_vectors.similarity('uncle','aunt'))\n",
    "print(word_vectors.similarity('boy','girl'))\n",
    "print(word_vectors.similarity('nephew','niece'))\n",
    "print(word_vectors.similarity('paper','water'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df92a0b9-74ed-41dd-92ef-0a41871c9d0f",
   "metadata": {},
   "source": [
    "in the above results we can see that the words that are related to each other have a high similarity sccore and the last words paper and water are not related to each other so their similarity score is very low as compared to the other words for which we have tested it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ef9354-a537-4e33-886f-529af44502a1",
   "metadata": {},
   "source": [
    "similarity between the vectors is generally calculated using the distance between the vectors of the words and then we are given a similarity score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5809d7e-4dd1-41a1-b49f-6d034b7f1939",
   "metadata": {},
   "source": [
    "### Finding Similar words to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d411273a-b9d7-41f8-9939-de063271d8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('towers', 0.8531750440597534), ('skyscraper', 0.6417425870895386), ('Tower', 0.639177143573761), ('spire', 0.594687819480896), ('responded_Understood_Atlasjet', 0.5931612253189087)]\n"
     ]
    }
   ],
   "source": [
    "# Find the top 5 words that are most similar in meaning to \"tower\"\n",
    "# The 'most_similar()' function calculates cosine similarity between\n",
    "# the vector for \"tower\" and all other word vectors in the vocabulary.\n",
    "# 'topn=5' means we only want the 5 closest (most similar) words.\n",
    "print(\n",
    "    word_vectors.most_similar(\n",
    "        \"tower\",   # the target word whose similar words we want\n",
    "        topn=5     # number of similar words to return\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f0c83b-a14a-425d-9a6b-c76c2077252d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
